# Data Analysis 2019 - LUCAS ROCHA

This project covers 3 sections of Data Analysis, Web Scrapping and Mining tasks

## Getting Started

These instructions will get you a copy of the project up and running on your local machine for development and testing purposes.

### Prerequisites

What things you need to use the application

```
Recent Windows Operational Systems
Python 3+
```

### Installing the dependencies

An automation script was provided to simplify virtual environment setup of the code.
To install and update all python dependencies, only in the first use, run:
```
install_requirements.bat
```

The libraries numpy, pandas, requests and selenium will be installed and
python / pip will be automatically updated.

Selenium is used because allows us to do dynamic scraping of non-static pages, and also can be used together with Beautiful Soup.
 Check the Selenium docs - [Documentation](https://selenium-python.readthedocs.io)


And after installation, for using the python script inside virtual enviroment, run:

```
* Execute_Part1A.bat ,
```
```
* Execute_Part1B.bat ,
```

```
* Execute_Part2.bat or
```
```
* Execute_Part3.bat
```

## Data Research and Integrity analysis

The Data research and integrity analysis texts can be found inside 'documents' folder, respectively
named as:
```
Lucas_Rocha_Part2_Answers.txt
```
```
Lucas_Rocha_Part3_Answers.txt
```

## Author

* **Lucas Rocha** - *Github Profile Link* - [Gitrocha](https://github.com/Gitrocha)
